{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e0395e",
   "metadata": {},
   "source": [
    "# 1.Data Injestion and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f939359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e097bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir good_data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3b9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir Bad_data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4789c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Path\n",
    "schema_file_path = 'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection\\\\schema_prediction.json'\n",
    "training_folder_path = 'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection\\\\Prediction_Batch_files/'\n",
    "good_data_folder_path = 'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection\\\\good_data_pred/'\n",
    "bad_data_folder_path = 'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection\\\\Bad_data_pred/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7149b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting values from predicted schema\n",
    "\n",
    "def valuesfromschema():\n",
    "    with open(schema_file_path, 'r') as f:\n",
    "        dic = json.load(f)\n",
    "        pattern = dic['SampleFileName']\n",
    "        LengthOfDateStampInFile = dic['LengthOfDateStampInFile']\n",
    "        LengthOfTimeStampInFile = dic['LengthOfTimeStampInFile']\n",
    "        column_names = dic['ColName']\n",
    "        NumberofColumns = dic['NumberofColumns']\n",
    "        \n",
    "        return pattern, LengthOfDateStampInFile, LengthOfTimeStampInFile, column_names, NumberofColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b72d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern, LengthOfDateStampInFile, LengthOfTimeStampInFile, column_names, NumberofColumns = valuesfromschema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43696f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regex\n",
    "def regex():\n",
    "    regex = \"['wafer']+['\\_'']+[\\d_]+[\\d]+\\.csv\"\n",
    "    return regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdffab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = regex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a86b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for filtering the good and bad  files\n",
    "def validate_file_name(regex, LengthOfDateStampInFile, LengthOfTimeStampInFile):\n",
    "    for filename in os.listdir(training_folder_path):\n",
    "        if (re.match(regex, filename)):\n",
    "            split_at_dot = re.split('.csv', filename)\n",
    "            split_at_dot = re.split('_', split_at_dot[0])\n",
    "            if len(split_at_dot[1]) == LengthOfDateStampInFile:\n",
    "                if len(split_at_dot[2]) == LengthOfTimeStampInFile:\n",
    "                    shutil.copy(f'{training_folder_path}'+filename , good_data_folder_path)\n",
    "                else:\n",
    "                    shutil.copy(f'{training_folder_path}'+filename , bad_data_folder_path)\n",
    "            else:\n",
    "                shutil.copy(f'{training_folder_path}'+filename , bad_data_folder_path)\n",
    "        else:\n",
    "                shutil.copy(f'{training_folder_path}'+filename , bad_data_folder_path)\n",
    "            \n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b956e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_file_name(regex, LengthOfDateStampInFile, LengthOfTimeStampInFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2173cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating column length in the file\n",
    "def validatecolumn(NumberofColumns):\n",
    "    for filename in os.listdir(good_data_folder_path):\n",
    "        csv = pd.read_csv(f'{good_data_folder_path}'+filename)\n",
    "        if csv.shape[1] == NumberofColumns:\n",
    "            pass\n",
    "        else:\n",
    "            shutil.copy(f'{good_data_folder_path}'+filename , bad_data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcb7f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validatecolumn(NumberofColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a879a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_missing_column():\n",
    "    for filename in os.listdir(good_data_folder_path):\n",
    "        csv = pd.read_csv(f'{good_data_folder_path}'+filename)\n",
    "        count=0\n",
    "        for column in csv:\n",
    "            if (len(csv[column])- csv[column].count()) == len(csv[column]):\n",
    "                count +=1\n",
    "                shutil.copy(f'{good_data_folder_path}'+filename , bad_data_folder_path)\n",
    "                break\n",
    "        if count==0:\n",
    "            csv.rename(columns = {'Unnamed: 0': \"wafer\"}, inplace = True)\n",
    "            csv.to_csv(f'{good_data_folder_path}'+ filename, index = None , header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8314ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_missing_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf14aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging or Combining all Data\n",
    "li = []\n",
    "for filename in os.listdir(good_data_folder_path):\n",
    "    csv = pd.read_csv(f'{good_data_folder_path}'+filename)\n",
    "    li.append(csv)\n",
    "\n",
    "combined_data = pd.concat(li , axis = 0, ignore_index=True)\n",
    "combined_data.to_csv('pred_main_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f347b8",
   "metadata": {},
   "source": [
    "# 2.Data_Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffceb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df = pd.read_csv('pred_main_data.csv')\n",
    "\n",
    "df\n",
    "\n",
    "# deleting unwanted column\n",
    "df.drop(columns = ['Unnamed: 0' , 'wafer'] , inplace = True)\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3, weights='uniform' , missing_values=np.nan)\n",
    "new_data = imputer.fit_transform(df)\n",
    "\n",
    "new_data = pd.DataFrame(new_data , columns= df.columns)\n",
    "new_data.to_csv('pred_clean_combined_data.csv')\n",
    "\n",
    "\n",
    "# # checking columns whihc have standard deviation of zero\n",
    "col_to_drop = []\n",
    "describe = df.describe()\n",
    "for x in new_data.columns:\n",
    "    if describe[x]['std']==0:\n",
    "        col_to_drop.append(x)\n",
    "\n",
    "col_to_drop\n",
    "new_data.drop(columns=col_to_drop, axis=1 , inplace=True)\n",
    "\n",
    "\n",
    "new_data.to_csv('pred_clean_data.csv' , index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6475694",
   "metadata": {},
   "source": [
    "# 3.Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e875e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv('pred_clean_data.csv')\n",
    "model = joblib.load('models/kmeans.pkl')\n",
    "y_pred = model.predict(data)\n",
    "data['cluster'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ffd5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('pred_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b2f54",
   "metadata": {},
   "source": [
    "# 4.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f1a3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = data['cluster'].unique()\n",
    "\n",
    "#loading all the models\n",
    "\n",
    "model_0 = joblib.load('models/random_forest_0.pkl')\n",
    "model_1 = joblib.load('models/xgboost_1.pkl')\n",
    "model_2 = joblib.load('models/random_forest_2.pkl')\n",
    "\n",
    "\n",
    "for i in clusters:\n",
    "    cluster_data = data[data['cluster']==i]\n",
    "#     wafer_names = list(data[''])\n",
    "    cluster_data = data.drop(columns='cluster' , axis = 1)\n",
    "    if i == 0:\n",
    "        predict_0 = model_0.predict(cluster_data)\n",
    "    if i == 1:\n",
    "        predict_1 = model_1.predict(cluster_data)\n",
    "    if i == 2:\n",
    "        predict_2 = model_2.predict(cluster_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b18569d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predict_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a75550d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1810529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ebe5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c94082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2a3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0efe458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0d9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea62a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
