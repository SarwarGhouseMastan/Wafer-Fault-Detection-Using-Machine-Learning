{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f2dbc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ae8a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c7148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is B21D-C88B\n",
      "\n",
      " Directory of C:\\Users\\User\\LearnBay\\ML Projects\\Wafer Fault Detection\n",
      "\n",
      "03/25/2022  05:08 PM    <DIR>          .\n",
      "03/25/2022  05:08 PM    <DIR>          ..\n",
      "03/25/2022  05:02 PM    <DIR>          .ipynb_checkpoints\n",
      "03/24/2022  06:27 PM    <DIR>          aaaaaaaaaaaa\n",
      "03/24/2022  05:07 PM    <DIR>          Afsaan codes\n",
      "03/24/2022  05:15 PM    <DIR>          Bad_data\n",
      "03/24/2022  05:03 PM    <DIR>          good_data\n",
      "03/24/2022  10:29 PM             9,756 part_1_data_injestion_validation.ipynb\n",
      "03/23/2022  08:13 PM            17,188 schema_prediction.json\n",
      "03/23/2022  08:13 PM            17,213 schema_training.json\n",
      "03/23/2022  08:26 PM    <DIR>          Training_Batch_Files\n",
      "03/25/2022  05:08 PM             2,461 Untitled.ipynb\n",
      "               4 File(s)         46,618 bytes\n",
      "               8 Dir(s)  139,803,762,688 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dbbdf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file good_data already exists.\n"
     ]
    }
   ],
   "source": [
    "mkdir good_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75e6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Bad_data already exists.\n"
     ]
    }
   ],
   "source": [
    "mkdir Bad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36b121d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Path\n",
    "schema_file_path = 'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection\\\\schema_training.json/'\n",
    "training_folder_path = 'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection\\\\Training_Batch_Files/'\n",
    "good_data_folder_path = 'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection\\\\good_data/'\n",
    "bad_data_folder_path = 'C:\\\\Users\\\\User\\\\LearnBay\\\\ML Projects\\\\Wafer Fault Detection\\\\Bad_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75d0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting values from predicted schema\n",
    "\n",
    "def valuesfromschema():\n",
    "    with open(schema_file_path, 'r') as f:\n",
    "        dic = json.load(f)\n",
    "        pattern = dic['SampleFileName']\n",
    "        LengthOfDateStampInFile = dic['LengthOfDateStampInFile']\n",
    "        LengthOfTimeStampInFile = dic['LengthOfTimeStampInFile']\n",
    "        column_names = dic['ColName']\n",
    "        NumberofColumns = dic['NumberofColumns']\n",
    "        \n",
    "        return pattern, LengthOfDateStampInFile, LengthOfTimeStampInFile, column_names, NumberofColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f581501",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern, LengthOfDateStampInFile, LengthOfTimeStampInFile, column_names, NumberofColumns = valuesfromschema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a04ac",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1ddec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex():\n",
    "    regex = \"['wafer']+['\\_'']+[\\d_]+[\\d]+\\.csv\"\n",
    "    return regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf7da1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = regex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c6451fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for filtering the good and bad  files\n",
    "def validate_file_name(regex, LengthOfDateStampInFile, LengthOfTimeStampInFile):\n",
    "    for filename in os.listdir(training_folder_path):\n",
    "        if (re.match(regex, filename)):\n",
    "            split_at_dot = re.split('.csv', filename)\n",
    "            split_at_dot = re.split('_', split_at_dot[0])\n",
    "            if len(split_at_dot[1]) == LengthOfDateStampInFile:\n",
    "                if len(split_at_dot[2]) == LengthOfTimeStampInFile:\n",
    "                    shutil.copy(f'{training_folder_path}'+filename , good_data_folder_path)\n",
    "                else:\n",
    "                    shutil.copy(f'{training_folder_path}'+filename , bad_data_folder_path)\n",
    "            else:\n",
    "                shutil.copy(f'{training_folder_path}'+filename , bad_data_folder_path)\n",
    "        else:\n",
    "                shutil.copy(f'{training_folder_path}'+filename , bad_data_folder_path)\n",
    "            \n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e76fe89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_file_name(regex, LengthOfDateStampInFile, LengthOfTimeStampInFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c753acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating column length in the file\n",
    "def validatecolumn(NumberofColumns):\n",
    "    for filename in os.listdir(good_data_folder_path):\n",
    "        csv = pd.read_csv(f'{good_data_folder_path}'+filename)\n",
    "        if csv.shape[1] == NumberofColumns:\n",
    "            pass\n",
    "        else:\n",
    "            shutil.copy(f'{good_data_folder_path}'+filename , bad_data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0785505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validatecolumn(NumberofColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "353742c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_missing_column():\n",
    "    for filename in os.listdir(good_data_folder_path):\n",
    "        csv = pd.read_csv(f'{good_data_folder_path}'+filename)\n",
    "        count=0\n",
    "        for column in csv:\n",
    "            if (len(csv[column])- csv[column].count()) == len(csv[column]):\n",
    "                count +=1\n",
    "                shutil.copy(f'{good_data_folder_path}'+filename , bad_data_folder_path)\n",
    "                break\n",
    "        if count==0:\n",
    "            csv.rename(columns = {'Unnamed: 0': \"wafer\"}, inplace = True)\n",
    "            csv.to_csv(f'{good_data_folder_path}'+ filename, index = None , header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66a78a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_missing_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186bf1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next Steps\n",
    "#Adding all data into Database\n",
    "# Empty good_data folder from the computer\n",
    "#Archive the Bad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4bcb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging or Combining all Data\n",
    "li = []\n",
    "for filename in os.listdir(good_data_folder_path):\n",
    "    csv = pd.read_csv(f'{good_data_folder_path}'+filename)\n",
    "    li.append(csv)\n",
    "\n",
    "combined_data = pd.concat(li , axis = 0, ignore_index=True)\n",
    "combined_data.to_csv('main_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
